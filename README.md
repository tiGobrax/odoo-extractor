# Odoo Extractor

[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue)](https://github.com/tiGobrax/odoo-extractor)

Extrator de dados do Odoo usando XML-RPC, com suporte a pagina√ß√£o autom√°tica, retry inteligente e exporta√ß√£o para Parquet usando Polars.

**Reposit√≥rio:** [https://github.com/tiGobrax/odoo-extractor](https://github.com/tiGobrax/odoo-extractor)

## üöÄ Caracter√≠sticas

- ‚úÖ Conex√£o segura via XML-RPC com autentica√ß√£o
- ‚úÖ Pagina√ß√£o autom√°tica para grandes volumes de dados
- ‚úÖ Retry inteligente com categoriza√ß√£o de erros (tempor√°rios vs permanentes)
- ‚úÖ Exporta√ß√£o para Parquet usando Polars
- ‚úÖ Timeout configur√°vel para requisi√ß√µes
- ‚úÖ Logging detalhado com Loguru
- ‚úÖ Suporte a Docker

## üß† Arquitetura em Alto N√≠vel

- **API FastAPI (`MODE=service`)** exp√µe endpoints para health check, atualiza√ß√£o/listagem do registry de models e execu√ß√£o incremental/full do ETL.
- **Cloud Run Job / batch (`MODE=job`)** reutiliza a mesma engine para full extract sem servidor HTTP (`app/jobs/full_extract_job.py`).
- **Engine (`app/engine`)** concentra regra de neg√≥cio: controle de cursores, sanitiza√ß√£o de registros, escrita em Parquet + upload no GCS.
- **Cliente Odoo (`src/odoo_extractor`)** encapsula autentica√ß√£o, pagina√ß√£o e pol√≠ticas de retry/classifica√ß√£o de erros da API XML-RPC.
- **Persist√™ncia (`src/storage.py`, `app/engine/cursor_store.py`, `app/engine/models_registry.py`)** escreve datasets, cursores incrementais e `models_list.csv` dentro do mesmo bucket/prefixo no GCS.
- **Ferramentas auxiliares**: script de an√°lise de Parquet (`parquet_analysis/`), manifests Terraform (`terraform/`) e guia de deploy no EKS (`DEPLOY.md`).

## üìã Pr√©-requisitos

- Python 3.11+
- Conta no Odoo com acesso √† API
- Vari√°veis de ambiente configuradas (veja `.env.example`)

## üß™ Setup e Execu√ß√£o Local (Python)

1. **Clonar e criar ambiente virtual**
   ```bash
   git clone https://github.com/tiGobrax/odoo-extractor
   cd odoo-extractor
   python -m venv .venv
   source .venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
2. **Configurar o arquivo `.env`**
   ```bash
   cp env.example .env
   # edite ODOO_URL/DB/USERNAME/PASSWORD e GOOGLE_APPLICATION_CREDENTIALS
   ```
3. **Executar a API (modo service, FastAPI)**
   ```bash
   MODE=service PORT=8080 python -m app.main
   # API dispon√≠vel em http://127.0.0.1:8080
   ```
4. **Executar um batch completo (modo job)**
   ```bash
   MODE=job ODOO_BATCH_SIZE=5000 python -m app.main
   ```
   O job usa `app/jobs/full_extract_job.py`, resolve a lista de models no registry (GCS) e grava Parquets diretamente no bucket configurado.

## üîß Execu√ß√£o com Docker

```bash
docker-compose up --build
```

Ou usando Docker diretamente:

```bash
docker build -t odoo-extractor .
docker run --env-file .env odoo-extractor
```

## ‚öôÔ∏è Configura√ß√£o

Crie um arquivo `.env` na raiz do projeto com as seguintes vari√°veis:

```env
ODOO_URL=https://seu-dominio.odoo.com
ODOO_DB=nome-do-banco
ODOO_USERNAME=seu-usuario@email.com
ODOO_PASSWORD=sua-api-key
GOOGLE_APPLICATION_CREDENTIALS=/app/creds/odoo-etl.json
```

### Vari√°veis de Ambiente

| Vari√°vel | Descri√ß√£o | Obrigat√≥ria | Padr√£o |
|----------|-----------|-------------|--------|
| `ODOO_URL` | URL base do Odoo | Sim | - |
| `ODOO_DB` | Nome do banco de dados | Sim | - |
| `ODOO_USERNAME` | Usu√°rio para autentica√ß√£o | Sim | - |
| `ODOO_PASSWORD` | API Key ou senha | Sim | - |
| `GOOGLE_APPLICATION_CREDENTIALS` | Caminho para o JSON da service account com acesso ao bucket (apenas fora do GCP) | N√£o | `/app/creds/odoo-etl.json` |
| `MODE` | Define se o processo sobe API (`service`) ou roda o job (`job`) | N√£o | `service` |
| `PORT` | Porta da API quando em modo servi√ßo | N√£o | `8080` |

## üß≠ Modos de Execu√ß√£o

| Modo | Vari√°vel | Entrypoint | Descri√ß√£o |
|------|----------|------------|-----------|
| Service (API) | `MODE=service` | `uvicorn app.api.app:app` (via `start.sh` ou `python -m app.main`) | Exp√µe endpoints REST para disparar extra√ß√µes, atualizar registry e health-check. |
| Job (batch) | `MODE=job` | `python -m app.main` ‚Üí `app/jobs/full_extract_job.py` | Executa full extract fora do contexto HTTP, ideal para Cloud Run Job, CronJob ou execu√ß√£o manual. |

Ambos os modos reutilizam `run_extraction` (em `app/engine/extractor.py`). A diferen√ßa √© somente o wrapper que aciona a engine.

## ‚òÅÔ∏è Armazenamento no Google Cloud Storage

Todos os datasets extra√≠dos s√£o enviados diretamente para o Google Cloud Storage. Cada model recebe sua pr√≥pria pasta abaixo do prefixo configurado (`GCS_BASE_PATH`), por exemplo:

- `gs://gobrax-data-lake/data-lake/odoo/stock_lot/<timestamp>.parquet`
- `gs://gobrax-data-lake/data-lake/odoo/account_account/<timestamp>.parquet`
- `gs://gobrax-data-lake/data-lake/odoo/crm_stage/<timestamp>.parquet`
- `gs://gobrax-data-lake/data-lake/odoo/models_list.csv`

O projeto **n√£o remove arquivos do GCS**, apenas adiciona novos Parquet a cada execu√ß√£o.

Todo arquivo inclui a coluna `ingestion_ts` em UTC (ISO 8601), permitindo filtrar facilmente o lote mais recente na camada silver.

Campos complexos (listas/dicion√°rios retornados por relacionamentos do Odoo) s√£o serializados como JSON para evitar inconsist√™ncias de tipo entre registros.

Al√©m dos Parquet, o mesmo bucket/prefixo hospeda:
- `models_list.csv`: resultado do `ModelsRegistry`, atualizado via endpoint `/models/update`.
- `cursors/<model>.json`: cursores incrementais (write_date/id) persistidos pela `CursorStore`.

Para rodar em Docker, monte o JSON da service account no container e aponte `GOOGLE_APPLICATION_CREDENTIALS` para o caminho interno. O `docker-compose.yml` de exemplo j√° exp√µe o segredo via volume somente leitura (`./odoo-etl@gobrax-data.iam.gserviceaccount.com.json:/app/creds/odoo-etl.json:ro`).
> ‚ÑπÔ∏è Os valores padr√£o de bucket/prefixo (`gobrax-data-lake` / `data-lake/odoo`) est√£o definidos nos m√≥dulos `src/storage.py`, `app/engine/cursor_store.py` e `app/engine/models_registry.py`. Ajuste-os se precisar apontar para outro data lake.

## üèÉ Rodar com Docker (Passo a Passo)

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/tiGobrax/odoo-extractor
cd odoo-extractor
```

### 2. Configure as vari√°veis de ambiente

Copie o arquivo de exemplo e edite com suas credenciais:

```bash
cp env.example .env
# Edite o arquivo .env com suas credenciais do Odoo
```

> üí° Posicione o arquivo JSON da service account na raiz do projeto e mantenha o nome configurado no `docker-compose.yml` (ou ajuste o volume) para que o container consiga ler `GOOGLE_APPLICATION_CREDENTIALS`.

### 3. Execute a aplica√ß√£o

**Op√ß√£o A: API (FastAPI com Uvicorn)**

```bash
docker compose up --build
```

A API estar√° dispon√≠vel em `http://127.0.0.1:18080` (o container escuta em `PORT=8000`, mas o `docker-compose.yml` publica `18080:8000`; sem override, o padr√£o interno √© `8080`).

**Op√ß√£o B: Execu√ß√£o batch (job)**

```bash
docker compose run --rm -e MODE=job odoo-extractor python -m app.main
```

### Atualizar registry de models (CSV no GCS)

1. **Garanta que a API esteja rodando localmente**:

   ```bash
   docker compose up --build
   ```

2. **Dispare a atualiza√ß√£o do registry** (o endpoint `/models/update` gera o `models_list.csv` dentro da pasta `odoo` no GCS):

   ```bash
   curl -X POST "http://127.0.0.1:18080/models/update"
   ```

### 4. Testar a API (se usando Op√ß√£o A)

Execute uma requisi√ß√£o para o endpoint de ETL:

```bash
curl -X POST "http://127.0.0.1:18080/run/inc"
```

### 5. Documenta√ß√£o da API (se usando FastAPI)

Acesse a documenta√ß√£o interativa em:
- Swagger UI: `http://127.0.0.1:18080/docs`
- ReDoc: `http://127.0.0.1:18080/redoc`

## üì° Endpoints da API

| M√©todo | Caminho | Descri√ß√£o |
|--------|---------|-----------|
| `GET` | `/health` | Health check simples. |
| `POST` | `/models/update` | Consulta `ir.model`, salva `models_list.csv` no GCS. |
| `GET` | `/models/list` | Retorna a lista atual armazenada no GCS. |
| `POST` | `/run/inc` | Executa extra√ß√£o incremental (default, usa cursor write_date/id). |
| `POST` | `/run/full` | Executa full refresh ignorando cursores. |
| `POST` | `/etl/run` | Endpoint legado, mant√©m comportamento incremental. |

Par√¢metros opcionais aceitos nos endpoints de ETL:
- `prefix`: apenas models cujo nome inicia com esse prefixo.
- `fields`: lista customizada de campos (default = todos).
- `limit`: limite de registros por model (apenas para troubleshooting).

## üßæ Registry de Models e Incremental

1. **Atualize o registry** (`/models/update`) sempre que novos models forem habilitados no Odoo. O arquivo `models_list.csv` fica no mesmo bucket/prefixo configurado na engine.
2. **Liste para verificar** (`/models/list`), especialmente antes de rodar jobs via linha de comando.
3. **Execute o ETL**:
   - Incremental (`/run/inc` ou `MODE=service`/`MODE=job` sem limpar cursores) usa `write_date` + `id` como cursor. Models sem `write_date` caem para full refresh automaticamente.
   - Full refresh (`/run/full` ou `MODE=job`) ignora cursores e n√£o atualiza `last_value`.
4. **Cursores** s√£o salvos em `cursors/<model>.json` contendo `cursor_field`, `last_value`, `last_id` e `updated_at`. Caso precise reiniciar de um ponto, remova o arquivo correspondente no bucket.
5. **Falhas controladas**:
   - Erros permanentes de schema/permiss√£o s√£o classificados como `skipped`.
   - Erros tempor√°rios disparam retry com backoff e reconex√£o autom√°tica da sess√£o XML-RPC.

## üìñ Uso

### Uso B√°sico

Para executar o pipeline completo sem subir a API, defina `MODE=job` e chame o mesmo entrypoint principal:

```bash
docker compose run --rm -e MODE=job odoo-extractor python -m app.main
```

Os Parquet s√£o gravados em `gs://gobrax-data-lake/data-lake/odoo/<model>/`.

## üîç An√°lise de Parquets (Ferramenta Auxiliar)

O script `parquet_analysis/analyze_parquets.py` ajuda a inspecionar arquivos no bucket, identificando campos que podem servir como cursor (`write_date`, `__last_update`, etc.), checando min/max/null e exibindo colunas com palavras-chave.

Uso t√≠pico:
```bash
python parquet_analysis/analyze_parquets.py \
  --bucket gobrax-data-lake \
  --base-path data-lake/odoo \
  --fields id name write_date \
  --search-terms write date last update \
  --limit 5
```

Principais par√¢metros:
- `--bucket` / `--base-path`: mesmo bucket/prefixo usado na engine.
- `--models`: restringe os models analisados; se omisso, lista automaticamente via prefixos do GCS.
- `--fields`: campos fixos que sempre aparecer√£o no relat√≥rio.
- `--search-terms`: termos (case-insensitive) para procurar colunas adicionais.
- `--ignore-fields`: remove campos espec√≠ficos mesmo que coincidam com termos.

O script baixa apenas o Parquet mais recente de cada model (pelo nome do arquivo) e exibe estat√≠sticas no terminal.

### Rodar an√°lise dentro de um container

Se quiser executar o analisador sem instalar depend√™ncias localmente, use o container oficial do Python montando o diret√≥rio do projeto e o JSON da service account:

```bash
docker run --rm -it \
  --env-file .env \
  -v "$(pwd)":/workspace \
  -v "$(pwd)/odoo-etl@gobrax-data.iam.gserviceaccount.com.json":/app/creds/odoo-etl.json:ro \
  -w /workspace \
  python:3.11-slim \
  bash -c "pip install --no-cache-dir -r requirements.txt && python parquet_analysis/analyze_parquets.py"
```

Esse comando instala as depend√™ncias necess√°rias dentro do container tempor√°rio (sem cache), reaproveita o `.env` local e garante que o script consiga acessar as credenciais do GCS em `/app/creds/odoo-etl.json`. Ajuste o caminho do JSON, par√¢metros do script ou `requirements.txt` se estiver usando outro nome/arquivo.

## ‚òÅÔ∏è Deploy no Cloud Run

O container exp√µe o FastAPI com Uvicorn via `start.sh` e automaticamente utiliza a porta definida pela vari√°vel `PORT` (Cloud Run define `PORT=8080`). Use o fluxo abaixo para garantir que a imagem publicada est√° alinhada com o que est√° no reposit√≥rio:

1. **Build e push da imagem para o Artifact Registry**
   ```bash
   export PROJECT_ID=gobrax-data           # ajuste conforme o seu projeto
   export REGION=us-central1
   export REPO=odoo-extractor
   export IMAGE_NAME=odoo-extractor

   gcloud builds submit \
     --tag ${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:latest
   ```

2. **Service Account e permiss√µes**
   ```bash
   gcloud iam service-accounts create odoo-extractor \
     --display-name="Service Account do Extrator Odoo"

   gcloud projects add-iam-policy-binding ${PROJECT_ID} \
     --member="serviceAccount:odoo-extractor@${PROJECT_ID}.iam.gserviceaccount.com" \
     --role="roles/storage.objectAdmin"
   gcloud projects add-iam-policy-binding ${PROJECT_ID} \
     --member="serviceAccount:odoo-extractor@${PROJECT_ID}.iam.gserviceaccount.com" \
     --role="roles/secretmanager.secretAccessor"
   ```

3. **Secrets e vari√°veis sens√≠veis**
   ```bash
   printf 'MINHA_API_KEY' | gcloud secrets create odoo-password --data-file=-
   gcloud secrets add-iam-policy-binding projects/${PROJECT_ID}/secrets/odoo-password \
     --member="serviceAccount:odoo-extractor@${PROJECT_ID}.iam.gserviceaccount.com" \
     --role="roles/secretmanager.secretAccessor"
   ```
   Configure os demais valores (URL, banco, usu√°rio) via `--set-env-vars`. Para o `ODOO_PASSWORD`, prefira `--set-secrets`, evitando expor o valor.

4. **Deploy da API**
   ```bash
   gcloud run deploy odoo-extractor \
     --image ${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:latest \
     --region ${REGION} --platform managed --allow-unauthenticated \
     --service-account odoo-extractor@${PROJECT_ID}.iam.gserviceaccount.com \
     --set-env-vars ODOO_URL=https://gobrax.odoo.com, \
                    ODOO_DB=gobrax-sh-main-22440471, \
                    ODOO_USERNAME=odoo@gobrax.com \
     --set-secrets ODOO_PASSWORD=odoo-password:latest
   ```
   > N√£o defina `GOOGLE_APPLICATION_CREDENTIALS` se estiver usando a service account do Cloud Run; o client do GCS utiliza Workload Identity automaticamente.

5. **Observabilidade e troubleshooting**
   - Logs do √∫ltimo deploy:  
     `gcloud run services describe odoo-extractor --region ${REGION} --format='value(status.latestReadyRevisionName)'`  
     `gcloud run logs read odoo-extractor --region ${REGION} --revision <revision>`
   - Quando o erro for ‚Äúcontainer failed to start‚Äù, quase sempre existe um stack trace nos logs de execu√ß√£o indicando vari√°vel ausente ou exce√ß√£o do Python.

Para execu√ß√µes batch (engine completa sem API), crie um Cloud Run Job reutilizando a mesma imagem e defina `MODE=job` (o `start.sh` j√° chama `python -m app.main`). Tamb√©m √© poss√≠vel orquestrar deltas chamando os endpoints `/run/inc` (incremental) ou `/run/full` (full refresh) via DAG sem necessidade de autentica√ß√£o adicional.

## üß± Provisionamento com Terraform

Se preferir automatizar toda a infraestrutura GCP (Artifact Registry, Secret Manager, service account e Cloud Run), utilize os manifests em `terraform/`.
> Para um guia completo de deploy no Amazon EKS (Jobs, CronJobs, IRSA, etc.), consulte `DEPLOY.md`.

1. Configure a autentica√ß√£o local (`gcloud auth application-default login` ou `GOOGLE_APPLICATION_CREDENTIALS`).
2. Copie o arquivo de vari√°veis e edite com seus valores:
   ```bash
   cd terraform
   cp terraform.tfvars.example terraform.tfvars
   # edite o arquivo e substitua tokens/senhas
   ```
3. Inicialize e valide:
   ```bash
   terraform init
   terraform plan
   ```
4. Caso o plano esteja correto, aplique:
   ```bash
   terraform apply
   ```

O m√≥dulo habilita as APIs necess√°rias, cria (ou confirma) o reposit√≥rio do Artifact Registry, provisiona a service account com as permiss√µes corretas, cadastra o segredo `odoo-password` e implanta o Cloud Run j√° apontando para a imagem informada. Ajuste `allow_unauthenticated=false` se quiser proteger o endpoint e forne√ßa um `invoker_identity` para controle fino de acesso.

### Uso Program√°tico

```python
from src.odoo_extractor.odoo_client import OdooClient

client = OdooClient()

# Extrair dados de um modelo
records = client.search_read(
    model="res.partner",
    domain=[],  # Filtros Odoo
    fields=client.get_all_fields("res.partner"),  # retorna todos os campos dispon√≠veis
    batch_size=5000,
    limit=None  # None para extrair todos
)

# Converter para Polars DataFrame
import polars as pl
df = pl.DataFrame(records)
```

### Par√¢metros do `search_read`

- `model` (str): Nome do modelo Odoo (ex: `res.partner`, `sale.order`)
- `domain` (list): Lista de filtros no formato Odoo (ex: `[('active', '=', True)]`)
- `fields` (list)`: Lista de campos a serem extra√≠dos. Se `None`, usamos `client.get_all_fields(model)` para buscar todos os campos dispon√≠veis.
- `batch_size` (int): Tamanho do lote para pagina√ß√£o (padr√£o: 5000)
- `limit` (int, opcional): Limite m√°ximo de registros a extrair

## üìÅ Estrutura do Projeto

```
odoo-extractor/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/                    # FastAPI + autentica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ engine/                 # Orquestra√ß√£o da extra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ jobs/                   # Entrypoints batch (Cloud Run Job)
‚îÇ   ‚îî‚îÄ‚îÄ main.py                 # Entrypoint √∫nico (MODE=service|job)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                # Normaliza√ß√£o de registros
‚îÇ   ‚îú‚îÄ‚îÄ storage.py              # Persist√™ncia em GCS (Polars)
‚îÇ   ‚îî‚îÄ‚îÄ odoo_extractor/         # Cliente XML-RPC, conex√£o e erros
‚îú‚îÄ‚îÄ start.sh                    # Script usado pelo container
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias Python
‚îú‚îÄ‚îÄ Dockerfile                  # Imagem Docker multi-stage
‚îú‚îÄ‚îÄ docker-compose.yml          # Configura√ß√£o para desenvolvimento local
‚îú‚îÄ‚îÄ .env.example                # Exemplo de vari√°veis de ambiente
‚îú‚îÄ‚îÄ terraform/                  # Provisionamento opcional na GCP
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```

## üß™ Testes

Ainda n√£o h√° su√≠te automatizada publicada neste reposit√≥rio. Recomendamos adicionar testes com `pytest` quando evoluir o projeto (por exemplo, cobrindo `OdooClient` com mocks de XML-RPC e o fluxo da engine).

## üîç Tratamento de Erros

O extrator categoriza automaticamente os erros:

- **Erros Tempor√°rios**: Timeouts, problemas de rede, servidor temporariamente indispon√≠vel
  - A√ß√£o: Retry autom√°tico (at√© 3 tentativas) com backoff exponencial
  
- **Erros Permanentes**: Campos inv√°lidos, modelos inexistentes, permiss√µes negadas
  - A√ß√£o: Log de aviso e continua√ß√£o com pr√≥ximo modelo

## üìù Logs

Os logs s√£o exibidos no console usando Loguru com emojis para facilitar a identifica√ß√£o:

- üîó Conex√£o estabelecida
- üì¶ Registros carregados
- ‚úÖ Sucesso
- ‚ö†Ô∏è Avisos
- ‚ùå Erros
- üö® Falhas cr√≠ticas

## üê≥ Docker

### Build da Imagem

```bash
docker build -t odoo-extractor .
```

### Executar Container

```bash
docker run --env-file .env odoo-extractor
```

### Docker Compose

```bash
docker-compose up
```

## ü§ù Contribuindo

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT.

## üêõ Problemas Conhecidos

- Alguns modelos podem ter campos que causam erros de schema (s√£o automaticamente ignorados)
- Timeouts podem ocorrer com modelos muito grandes (ajuste a vari√°vel `ODOO_BATCH_SIZE` antes da execu√ß√£o)

## üìû Suporte

Para problemas ou d√∫vidas, abra uma issue no reposit√≥rio.

